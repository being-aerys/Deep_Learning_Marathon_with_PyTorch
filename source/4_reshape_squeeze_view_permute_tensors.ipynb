{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: In numpy and torch, the specified axis or dim in any operation gets collapsed. In any tensor, axis/dim 0 is highest dimension, axis/dim 1 is the second-highest dimension and so on. For a 2D tensor, dim 0 is the row direction and dim1 is the column direction. For a 2D tensor, the sum/average/any operation across dim 0 will collapse the rows to produce only one row by performing the operation across the columnwise. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshaping\n",
    "Reshapes a tensor to a pre-defined shape. When possible, the returned tensor will be a view of input instead of a new copy. Otherwise, it will be a copy. Contiguous inputs and inputs with compatible strides can be reshaped without copying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a 1D tensor with 18 elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17]),\n",
       " torch.Size([18]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tensor = torch.arange(0,18,1)\n",
    "tensor, tensor.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While reshaping a tensor, the number of elements after the reshaping should match the number of elements before the reshaping. As such, product of dimensions before reshaping should equal the product of dimensions after reshaping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17]]),\n",
       " torch.Size([1, 18]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_reshaped = tensor.reshape(1,18)\n",
    "tensor_reshaped, tensor_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0],\n",
       "         [ 1],\n",
       "         [ 2],\n",
       "         [ 3],\n",
       "         [ 4],\n",
       "         [ 5],\n",
       "         [ 6],\n",
       "         [ 7],\n",
       "         [ 8],\n",
       "         [ 9],\n",
       "         [10],\n",
       "         [11],\n",
       "         [12],\n",
       "         [13],\n",
       "         [14],\n",
       "         [15],\n",
       "         [16],\n",
       "         [17]]),\n",
       " torch.Size([18, 1]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_reshaped = tensor.reshape(18, 1)\n",
    "tensor_reshaped, tensor_reshaped.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the addition of one extra dimension, represented by one extra pair of brackets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  1,  2,  3,  4,  5],\n",
       "         [ 6,  7,  8,  9, 10, 11],\n",
       "         [12, 13, 14, 15, 16, 17]]),\n",
       " torch.Size([3, 6]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_reshaped = tensor.reshape(3,6)\n",
    "tensor_reshaped, tensor_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0,  1,  2],\n",
       "          [ 3,  4,  5],\n",
       "          [ 6,  7,  8]],\n",
       " \n",
       "         [[ 9, 10, 11],\n",
       "          [12, 13, 14],\n",
       "          [15, 16, 17]]]),\n",
       " torch.Size([2, 3, 3]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_reshaped = tensor.reshape(2,3,3)\n",
    "tensor_reshaped, tensor_reshaped.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the product of the dimensions is preserved during the reshaping operation above.<br>\n",
    "18 == 3 * 6 == 2 * 3 * 3\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Viewing\n",
    "Returns a view of an input tensor of a user-assigned shape while keeping the state unchanged in memory. The returned tensor shares the same data and must have the same number of elements, but may have a different size. If it is not possible to view the tensor without copying to a new location in memory, view operation will fail and thus the reshape operation, instead of the view operation, should be used in the expense of a new copy in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3, 4, 5, 6, 7, 8]), torch.Size([9]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor =torch.arange(0,9)\n",
    "tensor, tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_viewed =  tensor.view(1,9)\n",
    "tensor_viewed, tensor_viewed.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the addition of one extra dimension, i.e., change in torch.Size attribute. Also both tensor and tensor_viewed share the same RAM memory. Hence, changing tensor_viewed also changes tensor in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[100,   1,   2,   3,   4,   5,   6,   7,   8]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_viewed[:,0] = 100\n",
    "tensor_viewed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([100,   1,   2,   3,   4,   5,   6,   7,   8])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that changing the element in the view changed the original tensor as well."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacking\n",
    "Concatenates a sequence of tensors along a new dimension provided as the argument. By default, the dim is 0, i.e., the highest dimension. Also, appends multiple tensors on top of each other (vstack) or side-by-side(hstack)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3]), torch.Size([3]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([1,2,3])\n",
    "tensor, tensor.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tensor` has only one dimension i.e., dim0 is the column dimension. However, for a list of tensors, dim0 becomes the row dimension and torch.stack() will use dim0 / row dimension as the highest dimension to stack the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [1, 2, 3],\n",
       "        [1, 2, 3]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_stacked = torch.stack([tensor, tensor, tensor], dim = 0)\n",
    "tensor_stacked"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if stacked at dim1, torch will stack the tensors along the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([1, 2, 3]), tensor([1, 2, 3]), tensor([1, 2, 3])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tensor, tensor, tensor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1],\n",
       "        [2, 2, 2],\n",
       "        [3, 3, 3]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_stacked = torch.stack([tensor, tensor, tensor], dim = 1)\n",
    "tensor_stacked"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some more examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2],\n",
       "        [3]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([[1],\n",
    "                       [2],\n",
    "                       [3]])\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[1],\n",
       "         [2],\n",
       "         [3]]),\n",
       " tensor([[1],\n",
       "         [2],\n",
       "         [3]]),\n",
       " tensor([[1],\n",
       "         [2],\n",
       "         [3]])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tensor, tensor, tensor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1],\n",
       "         [2],\n",
       "         [3]],\n",
       "\n",
       "        [[1],\n",
       "         [2],\n",
       "         [3]],\n",
       "\n",
       "        [[1],\n",
       "         [2],\n",
       "         [3]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_stacked = torch.stack([tensor, tensor, tensor], dim=0)\n",
    "tensor_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1],\n",
       "         [1],\n",
       "         [1]],\n",
       "\n",
       "        [[2],\n",
       "         [2],\n",
       "         [2]],\n",
       "\n",
       "        [[3],\n",
       "         [3],\n",
       "         [3]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_stacked = torch.stack([tensor, tensor, tensor], dim=1)\n",
    "tensor_stacked"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the original list of tensors had  2 dimensions. stack() operation added the third dimension."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.vstack() stacks tensors vertically/row wise while torch.hstack() stacks tensors horizontally / column wise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([4, 5, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.vstack((a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.hstack((a,b))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Squeeze and Unsqueeze\n",
    "Squeeze removes all 1 dimension from a tensor and unsqueeze adds a 1 dimension to a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([[[1,2,3],\n",
    "                       [4,5,6]]])\n",
    "torch.squeeze(tensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the removal of one dimension above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0.]]]]),\n",
       " torch.Size([1, 2, 3, 4]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.zeros(1,2,3,4)\n",
    "tensor, tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.squeeze(tensor) # can also use tensor.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.squeeze(tensor).shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unsqueezqe() returns a new tensor with a dimension of size 1 inserted at the specific dimension position provided by the user.\n",
    "explanation: https://stackoverflow.com/questions/57237352/what-does-unsqueeze-do-in-pytorch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### unsqueeze() for 1D tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3]), torch.Size([3]))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([1,2,3])\n",
    "tensor, tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3]]), torch.Size([1, 3]))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([1,2,3])\n",
    "unsqueezed = torch.unsqueeze(tensor, dim=0)\n",
    "unsqueezed, unsqueezed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1],\n",
       "         [2],\n",
       "         [3]]),\n",
       " torch.Size([3, 1]))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([1,2,3])\n",
    "unsqueezed = torch.unsqueeze(tensor, dim=1)\n",
    "unsqueezed, unsqueezed.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that a tensor with n dimensions can be unsqueezed only at dimensions between 0 and n-1, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-2, 1], but got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[85], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m3\u001b[39m])\n\u001b[1;32m----> 2\u001b[0m unsqueezed \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49munsqueeze(tensor, dim\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[0;32m      3\u001b[0m unsqueezed, unsqueezed\u001b[39m.\u001b[39mshape\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([1,2,3])\n",
    "unsqueezed = torch.unsqueeze(tensor, dim=2)\n",
    "unsqueezed, unsqueezed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### unsqueeze() for 2D tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3],\n",
       "         [4, 5, 6]]),\n",
       " torch.Size([2, 3]))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([[1,2,3],[4,5,6]])\n",
    "tensor, tensor.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the original 2D tensor has one no channel info, only rows and columns info since only 2 square brackets pairs at the ends of the tensor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6]]]),\n",
       " torch.Size([1, 2, 3]))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsqueezed = torch.unsqueeze(tensor, dim=0)\n",
    "unsqueezed, unsqueezed.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Squeezing it at dim 0 adds channel dimension i.e., 1 x 2 x 3 where 1 specifies that the tensor has only one channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3],\n",
       "         [4, 5, 6]]),\n",
       " torch.Size([2, 3]))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([[1,2,3],[4,5,6]])\n",
    "tensor, tensor.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3]],\n",
       " \n",
       "         [[4, 5, 6]]]),\n",
       " torch.Size([2, 1, 3]))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsqueezed = torch.unsqueeze(tensor, dim=1)\n",
    "unsqueezed, unsqueezed.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Squeezing it at dim 1 adds two channels instead of one channel and each channel contains one row and three columns, i.e., 2 x 1 x3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3],\n",
       "         [4, 5, 6]]),\n",
       " torch.Size([2, 3]))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([[1,2,3],[4,5,6]])\n",
    "tensor, tensor.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1],\n",
       "          [2],\n",
       "          [3]],\n",
       " \n",
       "         [[4],\n",
       "          [5],\n",
       "          [6]]]),\n",
       " torch.Size([2, 3, 1]))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsqueezed = torch.unsqueeze(tensor, dim=2)\n",
    "unsqueezed, unsqueezed.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Squeezing it at dim 2 gives out two channels and two rows but only 1 column, i.e., 2 x 3 x 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Permute\n",
    "Returns a **view** of the tensor with dimensions swapped in a certain way. Typically used with image data where images are of shape 224 x 224 x 3 where 224 and 224 represent the height and width of the image and 3 represents color channels R, B, G."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([224, 224, 3])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.rand((224, 224,3))\n",
    "tensor.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose, we want to use the color channel as the first dimension and the first dimension as the channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_permutted = tensor.permute(2,0,1) # where 2, 0, 1 are the dimension positions of color channels, height, width that we want to swap\n",
    "tensor_permutted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
